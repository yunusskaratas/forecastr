{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from flask_socketio import SocketIO, emit\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error\n",
    "from statsmodels.tsa import arima_model\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from copy import deepcopy\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "import itertools\n",
    "from numba import jit\n",
    "import sys\n",
    "from sklearn.externals import joblib\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import datetime\n",
    "import os\n",
    "import argparse\n",
    "from itertools import product\n",
    "import glob\n",
    "np.random.seed(0)\n",
    "\n",
    "import logging\n",
    "logging.captureWarnings(True)\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def check_val_of_forecast_settings(param):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Background:\n",
    "\n",
    "    This function is used to check to see if there is a value (submitted from the user in the UI) for a given Prophet Hyper Parameter. If there is no value or false or auto, return that, else we'll return a float of the param given that the value may be a string.\n",
    "\n",
    "    If the param value is blank, false or auto, it will eventually be excluding from the dictionary being passed in when instantiating Prophet.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Check hyper parameter value and return appropriate value.\n",
    "    if (param == \"\") or (param == False) or (param == 'auto'):\n",
    "        new_arg = param\n",
    "        return new_arg\n",
    "\n",
    "    else:\n",
    "        new_arg = float(param)\n",
    "        return new_arg\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecastr(data,forecast_settings,column_headers,freq_val,build_settings):\n",
    "\n",
    "    \"\"\"\n",
    "    Background: This function will take the data from the csv and forecast out x number of days.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    data: This is a pandas dataframe containing time series data, datetime first column\n",
    "    forecast_settings: This is a list containing values for model type, forecast period length,test_period and seasonality parameters\n",
    "    column_headers: List containing the name of the date and metric\n",
    "    freq_val: String containing \"D\",\"M\",\"Y\"\n",
    "    build_settings: String determining whether this is an initial or updated forecast.\n",
    "\n",
    "\n",
    "    Output:\n",
    "\n",
    "    [y_hat,dates,m,csv_ready_for_export]: A list containing forecasted data, dimension, model and data for the csv export\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    ##### Variables, Model Settings & Facebook Prophet Hyper Parameters #####\n",
    "\n",
    "    # Initial Variables\n",
    "    build = build_settings                                  # Determine the build_setting - either initial or update forecast settings.\n",
    "    dimension = column_headers[0]                           # date\n",
    "    metric = column_headers[1]                              # metric name\n",
    "\n",
    "    # Rename the columns so we can use FB Prophet\n",
    "    data=data.rename(columns={dimension: \"date\", metric: \"y\"}, inplace=True)\n",
    "    \n",
    "    # Hyper-parameters\n",
    "    fs_model_type = forecast_settings[0]                    # linear or logistic\n",
    "    fs_forecast_period = int(forecast_settings[1])                   # forecast period\n",
    "    fs_test_period=int(forecast_settings[2])# test period\n",
    "    if fs_model_type==\"Moving_Average\":\n",
    "        model_type=\"ma\"\n",
    "    '''\n",
    "    fs_seasonality_mode = forecast_settings[5]              # additive or multiplicative\n",
    "    fs_daily_seasonality = forecast_settings[7][0]          # True or False\n",
    "    fs_weekly_seasonality = forecast_settings[7][1]         # True or False\n",
    "    fs_yearly_seasonality = forecast_settings[7][2]         # True or False\n",
    "\n",
    "\n",
    "    # Need to set carrying capacity and saturated min as an int if model_type = 'logistic', else we'll set as 'auto' to be filtered out.\n",
    "\n",
    "    if fs_model_type == 'logistic':\n",
    "        fs_carrying_capacity = int(forecast_settings[2])        # int\n",
    "        fs_saturated_minimum = int(forecast_settings[3])        # int\n",
    "        data['cap'] = fs_carrying_capacity\n",
    "        data['floor'] = fs_saturated_minimum\n",
    "    else:\n",
    "        print('no cap or floor needed as it is a linear model.')\n",
    "        fs_carrying_capcity = 'auto'\n",
    "        fs_saturated_minimum = 'auto'\n",
    "\n",
    "    # Additional Hyper Parameters\n",
    "    fs_seasonality_prior_scale = forecast_settings[5]           # int\n",
    "    fs_n_changepoints = forecast_settings[7]                    # int\n",
    "    fs_changepoints_prior_scale = forecast_settings[8]          # int??\n",
    "\n",
    "\n",
    "    # Check the following hyper parameters to see if they were set from within the UI. If not, they'll be set to 'auto'\n",
    "    fs_seasonality_prior_scale = check_val_of_forecast_settings(fs_seasonality_prior_scale)\n",
    "    fs_n_changepoints = check_val_of_forecast_settings(fs_n_changepoints)\n",
    "    fs_changepoints_prior_scale = check_val_of_forecast_settings(fs_changepoints_prior_scale)\n",
    "\n",
    "    # Holidays - to be included in a future iteration....\n",
    "    holidays_prior_scale = 10 # Determines how much of an effect holidays should have on a prediction. Default value is 10\n",
    "\n",
    "    #### End of Hyper Parameters Settings ####\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "    '''    \n",
    "    # No let's set up the arguments so that we can pass them into Prophet() when we instantiate the model.\n",
    "\n",
    "    arguments = ['growth',\n",
    "                 'seasonality_mode',\n",
    "                 'seasonality_prior_scale',\n",
    "                 'daily_seasonality',\n",
    "                 'weekly_seasonality',\n",
    "                 'yearly_seasonality',\n",
    "                 'n_changepoints',\n",
    "                 'changepoint_prior_scale']\n",
    "\n",
    "    arg_values = [fs_model_type,\n",
    "                  fs_seasonality_mode,\n",
    "                  fs_seasonality_prior_scale,\n",
    "                  fs_daily_seasonality,\n",
    "                  fs_weekly_seasonality,\n",
    "                  fs_yearly_seasonality,\n",
    "                  fs_n_changepoints,\n",
    "                  fs_changepoints_prior_scale]\n",
    "\n",
    "    # Needs to be a dictionary\n",
    "    model_arg_vals = dict(zip(arguments,arg_values))\n",
    "\n",
    "\n",
    "    ###### CHECK TO SEE WHAT VALUES WERE SET FROM WITHIN THE UI ######\n",
    "\n",
    "    # Check to see if any values are 0, auto or false. If any hyper-parameters have these values, they will not be included\n",
    "    # when the pass in the dictionary prophet_arg_vals as kwarg\n",
    "\n",
    "    prophet_arg_vals = {}\n",
    "\n",
    "    for key,value in model_arg_vals.items():\n",
    "        if (value == \"\") or (value == False) or (value == 0) or (value == 'auto'):\n",
    "            print('skipping this key value pair')\n",
    "        else:\n",
    "            prophet_arg_vals[key] = value\n",
    "\n",
    "\n",
    "    ##### TIME TO INSTANTIATE, FIT AND PREDICT WITH FACEBOOK PROPHET ######\n",
    "    '''\n",
    "   \n",
    "    d = range(0,2)\n",
    "    p  = q = range(0, 3)\n",
    "    pdq = list(itertools.product(p, d, q))\n",
    "    m_1= range(0,13)\n",
    "    seasonal_pdq = [(x[0], x[1], x[2], x[3]) for x in list(itertools.product(p, d, q,m_1))]\n",
    "    pdq = pdq[1:]\n",
    "    \n",
    "    # Instantiate with prophet_arg_vals that are not auto, 0 or False.\n",
    "    result, model=prediction_func(data,pdq=pdq,seasonal_pdq=seasonal_pdq,test_day=fs_test_period,model_type=model_type)\n",
    "\n",
    "\n",
    "    # Status update\n",
    "    emit('processing', {'data': 'model has been fit'})\n",
    "\n",
    "\n",
    "    # Let's create a new data frame for the forecast which includes how long the user requested to forecast out in time units and by time unit type (eg. \"D\", \"M\",\"Y\")\n",
    "    #future = m.make_future_dataframe(periods=fs_period, freq=freq_val)\n",
    "\n",
    "    # If fs_model_type = 'logistic', create a column in future for carrying_capacity and saturated_minimum\n",
    "    '''\n",
    "    if fs_model_type == 'logistic':\n",
    "        future['cap'] = fs_carrying_capacity\n",
    "        future['floor'] = fs_saturated_minimum\n",
    "    else:\n",
    "        print('no cap or floor needed as it is a linear model.')\n",
    "'''\n",
    "    # Let's predict the future :)\n",
    "    y_forecast = model.forecast(fs_forecast_period+fs_test_period).tolist()\n",
    "    y.pop(0)\n",
    "    y_hat=model.predict().tolist()\n",
    "    preds=y_hat+y_forecast\n",
    "    ##### Send y_hat and dates to a list, so that they can be graphed easily when set in ChartJS\n",
    "    data_new=data.append(pd.DataFrame({\"date\": pd.date_range(start=data.date.iloc[-1], periods=7)}))\n",
    "    data_new[\"prediction\"]=preds\n",
    "    \n",
    "    #y_hat = data_new['preds'].tolist()\n",
    "    dates = data_new['date'].apply(lambda x: str(x).split(' ')[0]).tolist()\n",
    "\n",
    "    ##### Lets see how the forecast compares to historical performance #####\n",
    "\n",
    "    # First, lets sum up the forecasted metric\n",
    "    forecast_sum = y_hat.sum()\n",
    "    forecast_mean = y_hat.mean()\n",
    "\n",
    "\n",
    "\n",
    "    # Now lets sum up the actuals for the same time interval as we predicted\n",
    "    actual_sum = data_new[\"y\"].sum()\n",
    "    actual_mean = data_new[\"y\"].mean()\n",
    "\n",
    "    difference = '{0:.1%}'.format(((forecast_sum - actual_sum) / forecast_sum))\n",
    "    difference_mean = '{0:.1%}'.format(((forecast_mean - actual_mean) / forecast_mean))\n",
    "\n",
    "\n",
    "    forecasted_vals = ['{0:.1f}'.format(forecast_sum),'{0:.1f}'.format(actual_sum),difference]\n",
    "    forecasted_vals_mean = ['{0:.1f}'.format(forecast_mean),'{0:.1f}'.format(actual_mean),difference_mean]\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "\n",
    "    # Lets compare those two numbers, if forecast_sum is greater than actual, calculate the increase.  Else, calculate the decrease\n",
    "    if forecast_sum - actual_sum > 0:  # this if else handles percent increase vs. decrease\n",
    "        difference = '{0:.2%}'.format(((forecast_sum - actual_sum) / forecast_sum))\n",
    "        print(\"*********** DIFFERENCE IS ********\")\n",
    "        print(difference)\n",
    "    else:\n",
    "        difference = '{0:.2f}'.format(((actual_sum - forecast_sum) / actual_sum))\n",
    "        print(\"*********** DIFFERENCE IS ********\")\n",
    "        print(difference)\n",
    "\n",
    "    '''\n",
    "\n",
    "    ####### Formatting data for CSV Export Functionality ##########\n",
    "\n",
    "\n",
    "    # First, let's merge the original and forecast dataframes\n",
    "    #data_for_csv_export = pd.merge(forecast,data,on='date',how='left')\n",
    "\n",
    "    # Select the columns we want to include in the export\n",
    "    #export_formatted = data_for_csv_export[['ds','y','yhat','yhat_upper','yhat_lower']]\n",
    "    \n",
    "    # Rename y and yhat to the actual metric names\n",
    "    #export_formatted.rename(index=str, columns={'ds': 'date', 'y': metric, 'yhat': metric + '_forecast','yhat_upper':metric + '_upper_forecast','yhat_lower':metric + '_lower_forecast'}, inplace=True)\n",
    "\n",
    "    # replace NaN with an empty val\n",
    "    #export_formatted = export_formatted.replace(np.nan, '', regex=True)\n",
    "\n",
    "    # Format timestamp\n",
    "    #export_formatted['date'] = export_formatted['date'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "    # Create dictionary format for sending to csv\n",
    "    #csv_ready_for_export = export_formatted.to_dict('records')\n",
    "    csv_ready_for_export = data_new.to_dict('records')\n",
    "\n",
    "\n",
    "    # print(y_hat)\n",
    "    # print(csv_ready_for_export)\n",
    "    print(forecasted_vals)\n",
    "    print(forecasted_vals_mean)\n",
    "\n",
    "    return [preds,dates,model,csv_ready_for_export,forecasted_vals, forecasted_vals_mean]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    \"\"\"Calculates the mean absolute percentage error.\n",
    "    Args:\n",
    "    y_true: (np.array) actual values\n",
    "    y_pred: (np.array) predicted values\n",
    "    \n",
    "    Returns: \n",
    "    float value\"\"\"\n",
    "    \n",
    "\n",
    "    return np.mean(np.abs((y_true +0.00001*np.random.rand(len(y_true)) - y_pred+0.00001*np.random.rand(len(y_true))) / y_true+0.00001*np.random.rand(len(y_true)))) * 100\n",
    "\n",
    "\n",
    "def predict_sarimax_model(x_train,y_train,x_test,y_test,order,seasonal_order,feats_to_use=None,round_predictions=False,plot_results=True):\n",
    "    \n",
    "    #ipdb.set_trace()\n",
    "    \"\"\"\n",
    "    Predicts univariate predictions of data.\n",
    "    \n",
    "    Args:\n",
    "    x_train: (pandas dataframe) \n",
    "    y_train: (pandas dataframe)\n",
    "    x_test: (pandas dataframe) \n",
    "    y_test: (pandas dataframe)\n",
    "    order: (tuple) (p,d,q)\n",
    "    seasonal_order:(tuple) (P,D,Q,S)\n",
    "    feats_to_use: (list) exog features to use.\n",
    "    \n",
    "    Returns: \n",
    "    model_fit: (statsmodels object)\n",
    "    predictions: (pandas dataframe)\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = pd.Series()\n",
    "    y_train_history = y_train.copy()\n",
    "    \n",
    "    if feats_to_use is None:\n",
    "        feats_to_use = x_train.columns\n",
    "        \n",
    "    x_train_history = x_train[feats_to_use].copy()\n",
    "    for t in pd.DataFrame(y_test).iterrows():\n",
    "        model = SARIMAX(endog=y_train_history,exog=x_train_history[feats_to_use],order=order,seasonal_order=seasonal_order,\n",
    "                        enforce_stationarity=False,enforce_invertibility=False)\n",
    "        \n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast(exog=pd.DataFrame(x_test[feats_to_use].loc[t[0],:]).T)\n",
    "       \n",
    "        if output.iloc[0]< y_train.min() :\n",
    "            yhat = y_train.min()\n",
    "        elif output.iloc[0]> y_train.max() :\n",
    "            yhat =y_train.max()\n",
    "        else :\n",
    "            if round_predictions:\n",
    "                yhat = round(output.iloc[0],0)\n",
    "            else:\n",
    "                yhat = output.iloc[0]\n",
    "                \n",
    "        \n",
    "        if round_predictions:\n",
    "            predictions.loc[t[0]] = round(yhat,0)\n",
    "        else:\n",
    "            predictions.loc[t[0]] = yhat\n",
    "            \n",
    "        y_train_history.loc[t[0]] = t[1].values[0]\n",
    "        x_train_history.loc[t[0],:] = x_test[feats_to_use].loc[t[0],:]\n",
    "        #x_train_history  = pd.concat([x_train_history[feats_to_use],\n",
    "        #                              pd.DataFrame(x_test[feats_to_use].loc[t[0],:]).T],axis=0)\n",
    "        #print(\"Period: \",t[0],'predicted=%f, expected=%f' % (yhat,  t[1].values[0]))\n",
    "        #print(\"Period: \",t[0],'predicted=%f, expected=%f' % (yhat,  t[1].values[0]))\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        if plot_results:\n",
    "            mse_error = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "            mae_error = mean_absolute_error(y_test, predictions)\n",
    "            mape_error = mean_absolute_percentage_error(y_test.values, predictions.values)\n",
    "            \n",
    "            print('Test RMSE: %.3f' % mse_error)\n",
    "            print('Test MAE: %.3f' % mae_error)\n",
    "            print('Test MAPE: %.3f' % mape_error)\n",
    "        # plot\n",
    "        predictions = pd.DataFrame(data=y_test.values,index=y_test.index,columns=['actual']).merge(pd.DataFrame(data=predictions.values,\n",
    "                                                                                            index=predictions.index,columns=['predictions']),\n",
    "                                                                                            left_index=True,right_index=True)\n",
    "        predictions.plot()\n",
    "        plt.show()\n",
    "        print(model_fit.summary())\n",
    "        \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return model_fit,predictions\n",
    "\n",
    "\n",
    "                        \n",
    "def predict_sarima_model(train_set,test_set,order,seasonal_order,round_predictions=False,trend=None,plot_results=True):\n",
    "    \"\"\"\n",
    "    Predicts univariate predictions of data.\n",
    "    \n",
    "    Args:\n",
    "    train_set: (pandas dataframe) \n",
    "    test_set: (pandas dataframe)\n",
    "    order: (tuple) (p,d,q)\n",
    "    seasonal_order:(tuple) (P,D,Q,S)\n",
    "    \n",
    "    \n",
    "    Returns: \n",
    "    model_fit: (statsmodels object)\n",
    "    predictions: (pandas dataframe)\n",
    "    \"\"\"\n",
    "    \n",
    "    predictions = pd.Series()\n",
    "    historical_data = train_set.copy()\n",
    "\n",
    "    for t in pd.DataFrame(test_set).iterrows():\n",
    "        model = SARIMAX(historical_data,order=order,seasonal_order=seasonal_order, \\\n",
    "                        enforce_stationarity=False,enforce_invertibility=False,trend=trend)\n",
    "        \n",
    "        model_fit = model.fit(disp=0)\n",
    "        output = model_fit.forecast()\n",
    "\n",
    "        if output.iloc[0]< historical_data.min() :\n",
    "            yhat = historical_data.min()\n",
    "\n",
    "        elif output.iloc[0]> historical_data.max() :\n",
    "            yhat =historical_data.max()\n",
    "\n",
    "        else :\n",
    "            if round_predictions:\n",
    "                yhat = round(output.iloc[0],0)\n",
    "            else:\n",
    "                yhat = output.iloc[0]\n",
    "                \n",
    "        if round_predictions:\n",
    "            predictions.loc[t[0]] = round(yhat,0)\n",
    "        else:\n",
    "            predictions.loc[t[0]] = yhat\n",
    "        historical_data.loc[t[0]] = t[1].values[0]\n",
    "\n",
    "    predictions = pd.DataFrame(predictions,columns=['predictions']).merge(pd.DataFrame(test_set.values,index=test_set.index,columns=['actual']),left_index=True,right_index=True,how='left')\n",
    "\n",
    "    if plot_results:\n",
    "        mse_error = mean_squared_error(predictions['actual'], predictions['predictions'])\n",
    "        mae_error = mean_absolute_error(predictions['actual'], predictions['predictions'])\n",
    "        mape_error = mean_absolute_percentage_error(predictions['actual'].values, predictions['predictions'].values)\n",
    "\n",
    "        print('Test MSE: %.3f' % mse_error)\n",
    "        print('Test MAE: %.3f' % mae_error)\n",
    "        print('Test MAPE: %.3f' % mape_error)\n",
    "        print(model_fit.summary())\n",
    "        \n",
    "    predictions = pd.DataFrame(predictions,columns=['predictions']).merge(pd.DataFrame(test_set.values,index=test_set.index,columns=['actual']),left_index=True,right_index=True,how='left')\n",
    "    return model_fit,predictions\n",
    "\n",
    "@jit\n",
    "def grid_search_func(training_set,test_set,pdq,seasonal_pdq):\n",
    "    grid_results = pd.DataFrame(columns=['aic','param_significance','mape','mae'])\n",
    "\n",
    "    for tmp_pdq in pdq:\n",
    "        for tmp_s_pdq in seasonal_pdq:\n",
    "            tmp_model,tmp_pred_sarima = predict_sarima_model(train_set=training_set,\n",
    "                                                    test_set=test_set,\n",
    "                                                    order=tmp_pdq,seasonal_order= tmp_s_pdq ,plot_results = False)\n",
    "            \n",
    "            mae_error = mean_absolute_error(tmp_pred_sarima.actual, tmp_pred_sarima.predictions)\n",
    "            mape_error = mean_absolute_percentage_error(tmp_pred_sarima.actual.values, tmp_pred_sarima.predictions.values)\n",
    "            \n",
    "            res_key =  str(tmp_pdq) +\"|\" +str(tmp_s_pdq)\n",
    "            grid_results.loc[res_key,'aic'] = tmp_model.aic\n",
    "            grid_results.loc[res_key,'param_significance'] = (tmp_model.pvalues <0.1).all()\n",
    "            grid_results.loc[res_key,'mape'] = mape_error\n",
    "            grid_results.loc[res_key,'mae'] = mae_error\n",
    "            \n",
    "    return grid_results\n",
    "\n",
    "\n",
    "def multiprocessing(func, args,workers):\n",
    "    with ProcessPoolExecutor(max_workers=workers) as executor:\n",
    "        res = executor.map(func, args)\n",
    "    return list(res)\n",
    "\n",
    "def prediction_step(train_data,validation_data,test_data,pdq,seasonal_pdq,model_type):\n",
    "    #prediction_step(train_data,validation_data,test_data,pdq,seasonal_pdq,model_type='sarima')\n",
    "    #***********************************************************************************\n",
    "    \n",
    "     ## Find optimal params\n",
    "    try:\n",
    "        grid_search_results = grid_search_func(training_set=train_data,\n",
    "                               test_set=test_data,pdq=pdq,seasonal_pdq=seasonal_pdq).sort_values(by=['aic','mape'])\n",
    "\n",
    "        grid_pdq = ast.literal_eval(grid_search_results.index[3].split(\"|\")[0])\n",
    "        seasonal_grid_pdq = ast.literal_eval(grid_search_results.index[3].split(\"|\")[1])\n",
    "    except:\n",
    "        seasonal_grid_pdq = (0,0,0,0)\n",
    "        grid_pdq = (1,0,0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #***********************************************************************************\n",
    "    # Compare best prediction on validation set\n",
    "    \n",
    "    train_model = pd.concat([train_data,validation_data],axis=0)\n",
    "    print(train_data.columns)\n",
    "    if  ((train_data.shape[1]==1) & ((model_type==\"sarima\") | (model_type==None))): #use sarima\n",
    "        print(\"AAAA\")\n",
    "        \n",
    "        target_col=train_data.columns[0]\n",
    "        \n",
    "        \n",
    "        valid_sarima_model,valid_pred = predict_sarima_model(train_set=train_model.loc[:,target_col],\n",
    "                           test_set=validation_data.loc[:,target_col],\n",
    "                                        order=grid_pdq,\n",
    "                                        seasonal_order=seasonal_grid_pdq,\n",
    "         \n",
    "                                                                    plot_results = True,round_predictions=True)\n",
    "           # check accuracy of predictions\n",
    "        valid_pred_sarima=validation_data.copy()\n",
    "        valid_pred_sarima.loc[:,\"predictions\"]=valid_pred\n",
    "        mae_sarima = mean_absolute_error(valid_pred_sarima[target_col],valid_pred_sarima['predictions'])\n",
    "        \n",
    "        valid_ma = validation_data.copy()\n",
    "        valid_ma.loc[:,'predictions'] = round(train_data.loc[:,target_col].tail(4).mean())\n",
    "        mae_ma = mean_absolute_error(valid_ma[target_col],valid_ma['predictions'])\n",
    "        d = {'sarima':mae_sarima,'ma':mae_ma}\n",
    "        if model_type==None:\n",
    "            model_type = min(d,key=d.get)\n",
    "    \n",
    "    elif((train_data.shape[1]==1) & (model_type==\"ma\")): \n",
    "        target_col=train_data.columns[0]\n",
    "        valid_ma = validation_data.copy()\n",
    "        valid_ma.loc[:,'predictions'] = round(train_data.loc[:,target_col].tail(4).mean())\n",
    "        mae_ma = mean_absolute_error(valid_ma[target_col],valid_ma['predictions'])\n",
    "    else: #use SARIMAX \n",
    "        \n",
    "        print(\"enter there\")\n",
    "        target_col=train_data.iloc[:,-1].name\n",
    "        feature_cols= train_data.iloc[:,:-1]\n",
    "        \n",
    "        valid_sarimax_model,valid_pred_sarimax = predict_sarimax_model(x_train=train_model.loc[:,feature_cols],\n",
    "                                                                   y_train=train_model.loc[:,target_col],\n",
    "                                                                   x_test=validation_data.loc[:,feature_cols],\n",
    "                                                                   y_test=validation_data.loc[:,target_col],\n",
    "                                                                   order=grid_pdq, seasonal_order=seasonal_grid_pdq,\n",
    "                                                                   feats_to_use=feature_cols,round_predictions=True,\n",
    "                                                                   plot_results = True)\n",
    "        valid_pred_sarimax_table=validation_data.copy()\n",
    "        valid_pred_sarimax_table[\"predictions\"]=valid_pred_sarimax\n",
    "        # check accuracy of predictions\n",
    "        \n",
    "        mae_sarimax = mean_absolute_error(valid_pred_sarimax_table['actual'],valid_pred_sarimax_table['predictions'])\n",
    "    \n",
    "    \n",
    "    #***********************************************************************************\n",
    "    # Fit Model\n",
    "\n",
    "    if model_type=='sarima':\n",
    "        \n",
    "        try:\n",
    "            sarima_model,pred_sarima = predict_sarima_model(train_set=train_model.loc[:,target_col],\n",
    "                                       test_set=test_data.loc[:,target_col],\n",
    "                                                    order=grid_pdq,\n",
    "                                                    seasonal_order=seasonal_grid_pdq,\n",
    "                                                            plot_results = True,round_predictions=True)\n",
    "            \n",
    "            result = test_data.merge(pred_sarima,left_index=True,right_index=True)\n",
    "            result.loc[:,'model_type'] = 'sarima'\n",
    "            return [result,sarima_model]\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    elif model_type=='sarimax':\n",
    "    \n",
    "        try:\n",
    "            sarimax_model,pred_sarimax = predict_sarimax_model(x_train=train_model.loc[:,feature_cols],\n",
    "                                                               y_train=train_model.loc[:,target_col],\n",
    "                                                               x_test=test_data.loc[:,feature_cols], \n",
    "                                                               y_test=test_data.loc[:,target_col],\n",
    "                                                               order=grid_pdq,seasonal_order=seasonal_grid_pdq,\n",
    "                                                               feats_to_use=feature_cols,round_predictions=True,\n",
    "                                                               plot_results = True)\n",
    "            \n",
    "            result = test_data.merge(pred_sarimax,left_index=True,right_index=True)\n",
    "            result.loc[:,'model_type'] = 'sarimax'\n",
    "        except:\n",
    "            pass       \n",
    "    \n",
    "        \n",
    "    elif model_type==\"ma\":\n",
    "        result = test_data.copy()\n",
    "        result.loc[:,'predictions'] = round(train_model.loc[:,target_col].tail(4).mean())\n",
    "        result.loc[:,'model_type'] = 'ma'\n",
    "    #all_results = pd.concat([all_results,tmp_result],axis=0)\n",
    "    #***********************************************************************************\n",
    "    \n",
    "\n",
    "def prediction_func(data,pdq,seasonal_pdq,test_day,model_type,freq=\"D\"): \n",
    " \n",
    "    data.iloc[:,0]=pd.to_datetime(data.iloc[:,0])\n",
    "    data=data.set_index(list(data)[0])\n",
    "        \n",
    "    '''\n",
    "    test_date = pd.to_datetime(test_date)\n",
    "    test_date_end = test_date+ datetime.timedelta(days=4)\n",
    "    last_week = (pd.to_datetime(test_date) - datetime.timedelta(days=7))\n",
    "\n",
    "    train_data = data.loc[:last_week,:]\n",
    "    test_data = data.loc[test_date:test_date_end,:]\n",
    "    validation_data=data.loc[last_week:test_date,:]'''\n",
    "    valid_day=test_day+7\n",
    "    train_data=data.iloc[:valid_day]\n",
    "    test_data = data.iloc[-test_day:]\n",
    "    validation_data=data.iloc[-valid_day:-test_day]\n",
    "    # train/test/validation split\n",
    "    \n",
    "\n",
    "    if (train_data.shape[0] !=0) and (validation_data.shape[0] !=0) and (test_data.shape[0] !=0):\n",
    "        \n",
    "        if model_type==\"ma\":\n",
    "            result,model = prediction_step(train_data,validation_data,test_data,pdq=(1,0,0),seasonal_pdq=(0,0,0,0),model_type='ma')\n",
    "        else:\n",
    "            result,model = prediction_step(train_data,validation_data,test_data,pdq,seasonal_pdq,model_type=model_type)\n",
    "            \n",
    "        '''    \n",
    "        prediction_dir = \"/home/yunus-emre.karatas/time_series_tool/weekly_prediction/predictions/\" + str(datetime.datetime.now()).replace(\"-\",\"_\").replace(\" \",\"_\").split(\".\")[0].replace(\":\",\"_\") \n",
    "\n",
    "        Path(prediction_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        prediction_dir = prediction_dir +\"/\"\n",
    "            \n",
    "        \n",
    "        pred_file_name =prediction_dir+str(test_date)+ \"_\"+\".csv\"\n",
    "        result.to_csv(pred_file_name)'''\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "        \n",
    "    logging.captureWarnings(True)\n",
    "    warnings.filterwarnings(action='once')\n",
    "\n",
    "    return result,model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary_stats(data,column_headers):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Background:\n",
    "    This function will get some summary statistics about the original dataset being uploaded.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    data: a dataframe with the data from the uploaded csv containing a dimension and metric\n",
    "    column_headers: string of column names for the dimension and metric\n",
    "\n",
    "\n",
    "    Output:\n",
    "\n",
    "    sum_stats: a list containing the count of time units, the mean, std, min and max values of the metric. This data is rendered on step 2 of the UI.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Set the dimension and metrics\n",
    "    dimension = column_headers[0]\n",
    "    metric = column_headers[1]\n",
    "\n",
    "\n",
    "\n",
    "    time_unit_count = str(data[dimension].count())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print(data[metric].mean())\n",
    "\n",
    "    mean = str(round(data[metric].mean(),2))\n",
    "    print('string of the mean is ' + mean)\n",
    "\n",
    "\n",
    "    std = str(round(data[metric].std(),2))\n",
    "    minimum = str(round(data[metric].min(),2))\n",
    "    maximum = str(round(data[metric].max(),2))\n",
    "\n",
    "    sum_stats = [time_unit_count,mean,std,minimum,maximum]\n",
    "    print(sum_stats)\n",
    "\n",
    "    return sum_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_timeframe(data, time_unit):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Backgro\n",
    "\n",
    "    This function determines whether the data is daily, weekly, monthly or yearly by checking the delta between the first and second date in the df.\n",
    "\n",
    "    Input:\n",
    "\n",
    "    data: a df containg a dimension and a metric\n",
    "    time_unit: is the dimension name for the date.\n",
    "\n",
    "\n",
    "    Output:\n",
    "\n",
    "    time_list: a list of strings to be used within the UI (time, desc) and when using the function future = m.make_future_dataframe(periods=fs_period, freq=freq_val)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Determine whether the data is daily, weekly, monthly or yearly\n",
    "    date1 = data[time_unit][0]\n",
    "    date2 = data[time_unit][1]\n",
    "\n",
    "    first_date = pd.Timestamp(data[time_unit][0])\n",
    "    second_date = pd.Timestamp(data[time_unit][1])\n",
    "    time_delta = second_date - first_date\n",
    "\n",
    "    time_delta = int(str(time_delta).split(' ')[0])\n",
    "\n",
    "    print([data[time_unit][0],data[time_unit][1]])\n",
    "    print([second_date,first_date,time_delta])\n",
    "\n",
    "\n",
    "    if time_delta == 1:\n",
    "        time = 'days'\n",
    "        freq = 'D'\n",
    "        desc = 'daily'\n",
    "    elif time_delta >=7 and time_delta <= 27:\n",
    "        time = 'weeks'\n",
    "        freq = 'W'\n",
    "        desc = 'weekly'\n",
    "    elif time_delta >=28 and time_delta <=31:\n",
    "        time = 'months'\n",
    "        freq = 'M'\n",
    "        desc = 'monthly'\n",
    "    elif time_delta >= 364:\n",
    "        time = 'years'\n",
    "        freq = 'Y'\n",
    "        desc = 'yearly'\n",
    "    else:\n",
    "        print('error?')\n",
    "\n",
    "    time_list = [time,freq, desc]\n",
    "    #print(time_list)\n",
    "\n",
    "    return time_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Background: This function will determine which columns are dimensions (time_unit) vs metrics, in addition to reviewing the metric data to see if there are any objects in that column.\n",
    "\n",
    "    Input:\n",
    "\n",
    "        data (df): A dataframe of the parsed data that was uploaded.\n",
    "\n",
    "    Output:\n",
    "\n",
    "        [time_unit,metric_unit]: the appropriate column header names for the dataset.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Get list of column headers\n",
    "    column_headers = list(data) ## get column names\n",
    "\n",
    "\n",
    "    # Let's determine the column with a date\n",
    "\n",
    "    col1 = column_headers[0] \n",
    "    col2 = column_headers[1]\n",
    "    print('the first column is ' + col1)\n",
    "\n",
    "    # Get the first value in column 1, which is what is going to be checked.\n",
    "    col1_val = data[col1][0]\n",
    "    print(data.shape)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    TO DO: Pre-processing around the dtypes of both columns. If both are objects, I'll need to determine which is the column.\n",
    "\n",
    "    TO DO: Emit any error messaging\n",
    "\n",
    "\n",
    "    print('The data type of this metric column is: ' + str(data[metric].dtype))\n",
    "    print(data[metric].head())\n",
    "\n",
    "    data[metric] = data[metric].apply(lambda x: float(x))\n",
    "\n",
    "    print(data[metric].dtype)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check to see if the data has any null values\n",
    "\n",
    "    print('Is there any null values in this data? ' + str(data.isnull().values.any()))\n",
    "\n",
    "    # If there is a null value in the dataset, locate it and emit the location of the null value back to the client, else continue:\n",
    "\n",
    "    print(data.tail())\n",
    "\n",
    "    do_nulls_exist = data.isnull().values.any()\n",
    "\n",
    "    if do_nulls_exist == True:\n",
    "        print('found a null value')\n",
    "        null_rows = pd.isnull(data).any(1).nonzero()[0]\n",
    "        print('######### ORIGINAL ROWS THAT NEED UPDATING ##############')\n",
    "        print(null_rows)\n",
    "        # Need to add 2 to each value in null_rows because there\n",
    "\n",
    "        print('######### ROWS + 2 = ACTUAL ROW NUMBERS IN CSV ##############')\n",
    "        update_these_rows = []\n",
    "        for x in null_rows:\n",
    "            update_these_rows.append(int(x)+2)\n",
    "\n",
    "        print(update_these_rows)\n",
    "\n",
    "        emit('error', {'data': update_these_rows})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('no nulls found')\n",
    "\n",
    "\n",
    "    if isinstance(col1_val, (int, np.integer)) or isinstance(col1_val, float):\n",
    "        print(str(col1_val) + ' this is a metric')\n",
    "        print('Setting time_unit as the second column')\n",
    "        time_unit = column_headers[1]\n",
    "        metric_unit = column_headers[0]\n",
    "        return [time_unit, metric_unit]\n",
    "    else:\n",
    "        print('Setting time_unit as the first column')\n",
    "        time_unit = column_headers[0]\n",
    "        metric_unit = column_headers[1]\n",
    "        return [time_unit, metric_unit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##not alive\n",
    "def validate_model(model,dates):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Background:\n",
    "\n",
    "    This model validation function is still under construction and will be updated during a future release.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    count_of_time_units = len(dates)\n",
    "    #print(count_of_time_units)\n",
    "    initial_size = str(int(count_of_time_units * 0.20)) + \" days\"\n",
    "    horizon_size = str(int(count_of_time_units * 0.10)) + \" days\"\n",
    "    period_size = str(int(count_of_time_units * 0.05)) + \" days\"\n",
    "\n",
    "    df_cv = cross_validation(model, initial=initial_size, horizon=horizon_size, period=period_size)\n",
    "    #df_cv = cross_validation(model,initial='730 days', period='180 days', horizon = '365 days')\n",
    "    df_p = performance_metrics(df_cv)\n",
    "\n",
    "    #print(df_cv.head(100))\n",
    "    #print(df_p.head(100))\n",
    "\n",
    "    mape_score_avg = str(round(df_p['mape'].mean()*100,2)) + \"%\"\n",
    "\n",
    "    return mape_score_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
